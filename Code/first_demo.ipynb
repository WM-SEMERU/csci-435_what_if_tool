{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "619519a8",
   "metadata": {},
   "source": [
    "# Initial Commit\n",
    "First py notebook for full run through of data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f4e363f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import pipeline, set_seed\n",
    "\n",
    "\n",
    "training_text_filename = \"method-generation.txt\"\n",
    "training_text_file_location = os.path.join(os.getcwd(), \"Train\", \"method-generation.txt\")\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a6e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_text_file_location) as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b146ea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:  <class 'list'>\n",
      "[\"class Beam(object):\\n    def __init__(self, size, sos, eos):\\n        self.size = size\\n        self.tt = torch.cuda\\n\\nassert(\\n\\nself.size / 2 == 0)\\n\\n''\\n\\n```\", 'class Beam(object):\\n    def __init__(self, size, sos, eos):\\n        self.size = size\\n        self.tt = torch.cuda\\n\\n# Create beam type\\n\\nstruct Beam: [UART, XAMB] {\\n', 'class Beam(object):\\n    def __init__(self, size, sos, eos):\\n        self.size = size\\n        self.tt = torch.cuda\\n\\ndef __new__(self, name):      if name: self.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generated_text = generator(data, max_new_tokens=20, num_return_sequences=3)\n",
    "\n",
    "for a in range(len(generated_text)):\n",
    "    generated_text[a] = generated_text[a]['generated_text']\n",
    "\n",
    "print(\"Type: \", type(generated_text))\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4ea1721d7fadea24e6840e529925348c2b6e25559d8bb511c630e839167e4b7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
